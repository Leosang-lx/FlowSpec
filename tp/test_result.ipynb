{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "209f1592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import os\n",
    "\n",
    "def load(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        obj = pickle.load(f)\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "3dca106b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test_tp/rank1_prenorm.pt\n",
      "Loading test_tp/rank1_qkv.pt\n",
      "Loading test_tp/rank1_attn_weights.pt\n",
      "Loading test_tp/rank1_attn_output.pt\n",
      "Loading test_tp/rank1_after_residual1.pt\n",
      "Loading test_tp/rank1_postnorm.pt\n",
      "Loading test_tp/rank1_up_proj.pt\n",
      "Loading test_tp/rank1_down_proj.pt\n",
      "Loading test_tp/rank1_after_residual2.pt\n",
      "Loading test_tp/rank2_prenorm.pt\n",
      "Loading test_tp/rank2_qkv.pt\n",
      "Loading test_tp/rank2_attn_weights.pt\n",
      "Loading test_tp/rank2_attn_output.pt\n",
      "Loading test_tp/rank2_after_residual1.pt\n",
      "Loading test_tp/rank2_postnorm.pt\n",
      "Loading test_tp/rank2_up_proj.pt\n",
      "Loading test_tp/rank2_down_proj.pt\n",
      "Loading test_tp/rank2_after_residual2.pt\n",
      "Loading test_tp/rank3_prenorm.pt\n",
      "Loading test_tp/rank3_qkv.pt\n",
      "Loading test_tp/rank3_attn_weights.pt\n",
      "Loading test_tp/rank3_attn_output.pt\n",
      "Loading test_tp/rank3_after_residual1.pt\n",
      "Loading test_tp/rank3_postnorm.pt\n",
      "Loading test_tp/rank3_up_proj.pt\n",
      "Loading test_tp/rank3_down_proj.pt\n",
      "Loading test_tp/rank3_after_residual2.pt\n",
      "Loading test_tp/rank4_prenorm.pt\n",
      "Loading test_tp/rank4_qkv.pt\n",
      "Loading test_tp/rank4_attn_weights.pt\n",
      "Loading test_tp/rank4_attn_output.pt\n",
      "Loading test_tp/rank4_after_residual1.pt\n",
      "Loading test_tp/rank4_postnorm.pt\n",
      "Loading test_tp/rank4_up_proj.pt\n",
      "Loading test_tp/rank4_down_proj.pt\n",
      "Loading test_tp/rank4_after_residual2.pt\n",
      "Loading test_ga/rank1_prenorm.pt\n",
      "Loading test_ga/rank1_qkv.pt\n",
      "Loading test_ga/rank1_attn_weights.pt\n",
      "Loading test_ga/rank1_attn_output.pt\n",
      "Loading test_ga/rank1_after_residual1.pt\n",
      "Loading test_ga/rank1_postnorm.pt\n",
      "Loading test_ga/rank1_up_proj.pt\n",
      "Loading test_ga/rank1_down_proj.pt\n",
      "Loading test_ga/rank1_after_residual2.pt\n",
      "Loading test_ga/rank2_prenorm.pt\n",
      "Loading test_ga/rank2_qkv.pt\n",
      "Loading test_ga/rank2_attn_weights.pt\n",
      "Loading test_ga/rank2_attn_output.pt\n",
      "Loading test_ga/rank2_after_residual1.pt\n",
      "Loading test_ga/rank2_postnorm.pt\n",
      "Loading test_ga/rank2_up_proj.pt\n",
      "Loading test_ga/rank2_down_proj.pt\n",
      "Loading test_ga/rank2_after_residual2.pt\n",
      "Loading test_ga/rank3_prenorm.pt\n",
      "Loading test_ga/rank3_qkv.pt\n",
      "Loading test_ga/rank3_attn_weights.pt\n",
      "Loading test_ga/rank3_attn_output.pt\n",
      "Loading test_ga/rank3_after_residual1.pt\n",
      "Loading test_ga/rank3_postnorm.pt\n",
      "Loading test_ga/rank3_up_proj.pt\n",
      "Loading test_ga/rank3_down_proj.pt\n",
      "Loading test_ga/rank3_after_residual2.pt\n",
      "Loading test_ga/rank4_prenorm.pt\n",
      "Loading test_ga/rank4_qkv.pt\n",
      "Loading test_ga/rank4_attn_weights.pt\n",
      "Loading test_ga/rank4_attn_output.pt\n",
      "Loading test_ga/rank4_after_residual1.pt\n",
      "Loading test_ga/rank4_postnorm.pt\n",
      "Loading test_ga/rank4_up_proj.pt\n",
      "Loading test_ga/rank4_down_proj.pt\n",
      "Loading test_ga/rank4_after_residual2.pt\n"
     ]
    }
   ],
   "source": [
    "ranks = [1, 2, 3, 4]\n",
    "ts = ['prenorm', 'qkv', 'attn_weights', 'attn_output', 'after_residual1', 'postnorm', 'up_proj', 'down_proj', 'after_residual2']\n",
    "\n",
    "def load_outputs(ranks, ts, dir):\n",
    "    res_dir = {}\n",
    "    for rank in ranks:\n",
    "        for t in ts:\n",
    "            name = f'rank{rank}_{t}'\n",
    "            path = os.path.join(dir, f'{name}.pt')\n",
    "            if os.path.exists(path):\n",
    "                print(f'Loading {path}')\n",
    "                tensor = load(path)\n",
    "                res_dir[name] = tensor\n",
    "            else:\n",
    "                raise FileNotFoundError(f'{path} does not exist')\n",
    "    return res_dir\n",
    "\n",
    "tpss = ['test_tp', 'test_ga']\n",
    "\n",
    "results = {\n",
    "    'test_tp': load_outputs(ranks, ts, 'test_tp'),\n",
    "    'test_ga': load_outputs(ranks, ts, 'test_ga'),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "ea9025ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_partial_results(pt):\n",
    "    names = [f'rank{rank}_{pt}' for rank in ranks]\n",
    "    partial = {\n",
    "        'tp': {name: results[f'test_tp'][name] for name in names},\n",
    "        'ga': {name: results[f'test_ga'][name] for name in names},\n",
    "    }\n",
    "    return names, partial\n",
    "\n",
    "def all_tensors_equal(tensor_list):\n",
    "    if not tensor_list:\n",
    "        return True\n",
    "    try:\n",
    "        stacked = torch.stack(tensor_list)  # 要求所有张量可堆叠（shape/dtype/device 一致）\n",
    "        return (stacked == stacked[0]).all().item()\n",
    "    except RuntimeError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "68c54cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank1_prenorm torch.Size([1, 140, 4096])\n",
      "rank2_prenorm torch.Size([1, 140, 4096])\n",
      "rank3_prenorm torch.Size([1, 140, 4096])\n",
      "rank4_prenorm torch.Size([1, 140, 4096])\n",
      "rank1_prenorm torch.Size([1, 35, 4096])\n",
      "rank2_prenorm torch.Size([1, 35, 4096])\n",
      "rank3_prenorm torch.Size([1, 35, 4096])\n",
      "rank4_prenorm torch.Size([1, 35, 4096])\n",
      "True\n",
      "tensor([[[-3.9244e-04, -1.1467e-02,  1.2197e-03,  ...,  3.0197e-02,\n",
      "           4.0741e-03, -2.5726e-02],\n",
      "         [ 1.6138e-01,  2.2034e-01, -1.9568e-01,  ...,  1.2805e-01,\n",
      "          -1.5869e-01,  1.3049e-01],\n",
      "         [-5.9473e-01,  8.5693e-01, -1.1432e-01,  ...,  6.9458e-02,\n",
      "           2.0422e-01, -3.9948e-02],\n",
      "         ...,\n",
      "         [-1.4477e-03,  1.1536e-02,  3.6157e-01,  ...,  1.4319e-01,\n",
      "          -3.3472e-01,  6.7676e-01],\n",
      "         [-4.1602e-01, -8.2568e-01, -1.4307e-01,  ..., -5.8301e-01,\n",
      "          -2.5366e-01,  5.9570e-01],\n",
      "         [-1.2732e-01,  3.8110e-01, -1.9092e-01,  ..., -2.6123e-01,\n",
      "          -3.5156e-01,  3.3374e-01]]], dtype=torch.float16) tensor([[[-4.0102e-04, -1.1345e-02,  1.1911e-03,  ...,  3.0228e-02,\n",
      "           4.0092e-03, -2.5665e-02],\n",
      "         [ 1.6187e-01,  2.2070e-01, -1.9653e-01,  ...,  1.2805e-01,\n",
      "          -1.5784e-01,  1.3135e-01],\n",
      "         [-5.9766e-01,  8.5840e-01, -1.1487e-01,  ...,  7.0618e-02,\n",
      "           2.0471e-01, -3.9581e-02],\n",
      "         ...,\n",
      "         [ 1.1301e-03,  1.2611e-02,  3.6157e-01,  ...,  1.4209e-01,\n",
      "          -3.3496e-01,  6.7529e-01],\n",
      "         [-4.1455e-01, -8.2568e-01, -1.4331e-01,  ..., -5.8447e-01,\n",
      "          -2.5342e-01,  5.9473e-01],\n",
      "         [-1.2683e-01,  3.8062e-01, -1.9238e-01,  ..., -2.6001e-01,\n",
      "          -3.5303e-01,  3.3276e-01]]], dtype=torch.float16)\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# prenorm\n",
    "pt = 'prenorm'\n",
    "names, partial = get_partial_results(pt)\n",
    "\n",
    "# first layer\n",
    "def check_prenorm():\n",
    "    for k, v in partial['tp'].items():\n",
    "        print(k, v.shape)\n",
    "    for k, v in partial['ga'].items():\n",
    "        print(k, v.shape)\n",
    "    \n",
    "    for name in names:\n",
    "        print(torch.allclose(partial['tp'][name], partial['ga'][name]))\n",
    "\n",
    "# second layer\n",
    "def check_prenorm():\n",
    "    for k, v in partial['tp'].items():\n",
    "        print(k, v.shape)\n",
    "    for k, v in partial['ga'].items():\n",
    "        print(k, v.shape)\n",
    "\n",
    "    prenorm_tp = [partial['tp'][name] for name in names]\n",
    "\n",
    "    print(all_tensors_equal(prenorm_tp))\n",
    "    prenorm_ga = torch.cat([partial['ga'][name] for name in names], dim=-2)\n",
    "    print(prenorm_tp[0], prenorm_ga)\n",
    "    print(torch.allclose(prenorm_tp[0], prenorm_ga, atol=1e-2))\n",
    "\n",
    "\n",
    "check_prenorm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "e51aa2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank1_qkv torch.Size([1, 140, 1024]) torch.Size([1, 140, 1024]) torch.Size([1, 140, 1024])\n",
      "rank2_qkv torch.Size([1, 140, 1024]) torch.Size([1, 140, 1024]) torch.Size([1, 140, 1024])\n",
      "rank3_qkv torch.Size([1, 140, 1024]) torch.Size([1, 140, 1024]) torch.Size([1, 140, 1024])\n",
      "rank4_qkv torch.Size([1, 140, 1024]) torch.Size([1, 140, 1024]) torch.Size([1, 140, 1024])\n",
      "rank1_qkv torch.Size([1, 140, 1024]) torch.Size([1, 140, 1024]) torch.Size([1, 140, 1024])\n",
      "rank2_qkv torch.Size([1, 140, 1024]) torch.Size([1, 140, 1024]) torch.Size([1, 140, 1024])\n",
      "rank3_qkv torch.Size([1, 140, 1024]) torch.Size([1, 140, 1024]) torch.Size([1, 140, 1024])\n",
      "rank4_qkv torch.Size([1, 140, 1024]) torch.Size([1, 140, 1024]) torch.Size([1, 140, 1024])\n",
      "False False False\n",
      "False False False\n",
      "False False False\n",
      "False False False\n"
     ]
    }
   ],
   "source": [
    "# qkv\n",
    "pt = 'qkv'\n",
    "names, partial = get_partial_results(pt)\n",
    "\n",
    "# first layer (tp)\n",
    "def check_qkv():\n",
    "    for k, v in partial['tp'].items():\n",
    "        print(k, v[0].shape, v[1].shape, v[2].shape)\n",
    "    for k, v in partial['ga'].items():\n",
    "        print(k, v[0].shape, v[1].shape, v[2].shape)\n",
    "    \n",
    "    for name in names:\n",
    "        q1, k1, v1 = partial['tp'][name]\n",
    "        q2, k2, v2 = partial['ga'][name]\n",
    "        print(torch.allclose(q1, q2, atol=5e-3), torch.allclose(k1, k2, atol=8e-3), torch.allclose(v1, v2, atol=8e-3))\n",
    "\n",
    "# second layer (galaxy)\n",
    "\n",
    "check_qkv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "6627a123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank1_attn_weights torch.Size([1, 8, 140, 140])\n",
      "rank2_attn_weights torch.Size([1, 8, 140, 140])\n",
      "rank3_attn_weights torch.Size([1, 8, 140, 140])\n",
      "rank4_attn_weights torch.Size([1, 8, 140, 140])\n",
      "rank1_attn_weights torch.Size([1, 8, 140, 140])\n",
      "rank2_attn_weights torch.Size([1, 8, 140, 140])\n",
      "rank3_attn_weights torch.Size([1, 8, 140, 140])\n",
      "rank4_attn_weights torch.Size([1, 8, 140, 140])\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# attn_weight\n",
    "pt = 'attn_weights'\n",
    "names, partial = get_partial_results(pt)\n",
    "\n",
    "def check_attn_weight():\n",
    "    for k, v in partial['tp'].items():\n",
    "        print(k, v.shape)\n",
    "    for k, v in partial['ga'].items():\n",
    "        print(k, v.shape)\n",
    "    \n",
    "    for name in names:\n",
    "        print(torch.allclose(partial['tp'][name], partial['ga'][name], atol=5e-3))\n",
    "\n",
    "check_attn_weight()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "07bb6830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank1_attn_output torch.Size([1, 140, 4096])\n",
      "rank2_attn_output torch.Size([1, 140, 4096])\n",
      "rank3_attn_output torch.Size([1, 140, 4096])\n",
      "rank4_attn_output torch.Size([1, 140, 4096])\n",
      "rank1_attn_output torch.Size([1, 35, 4096])\n",
      "rank2_attn_output torch.Size([1, 35, 4096])\n",
      "rank3_attn_output torch.Size([1, 35, 4096])\n",
      "rank4_attn_output torch.Size([1, 35, 4096])\n",
      "tensor([[[ 0.0553, -0.0155,  0.0037,  ..., -0.2419,  0.1694,  0.1458],\n",
      "         [-0.1049, -0.1730,  0.0094,  ..., -0.1145,  0.1742,  0.3442],\n",
      "         [-0.0434, -0.4470,  0.1958,  ...,  0.1692, -0.0738,  0.1276],\n",
      "         ...,\n",
      "         [ 0.2024, -0.2805, -0.3152,  ...,  0.0519,  0.0266,  0.1704],\n",
      "         [ 0.5674,  0.2612, -0.3511,  ...,  0.0698,  0.1479,  0.1974],\n",
      "         [ 0.0319, -0.0128, -0.0957,  ..., -0.2676,  0.0244,  0.2534]]],\n",
      "       dtype=torch.float16)\n",
      "tensor([[[ 0.0552, -0.0157,  0.0037,  ..., -0.2419,  0.1696,  0.1458],\n",
      "         [-0.1046, -0.1736,  0.0090,  ..., -0.1145,  0.1738,  0.3435],\n",
      "         [-0.0429, -0.4482,  0.1951,  ...,  0.1693, -0.0741,  0.1267],\n",
      "         ...,\n",
      "         [ 0.2000, -0.2805, -0.3147,  ...,  0.0554,  0.0273,  0.1719],\n",
      "         [ 0.5654,  0.2607, -0.3508,  ...,  0.0697,  0.1484,  0.1965],\n",
      "         [ 0.0315, -0.0128, -0.0962,  ..., -0.2666,  0.0247,  0.2529]]],\n",
      "       dtype=torch.float16)\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# attn_output\n",
    "pt = 'attn_output'\n",
    "names, partial = get_partial_results(pt)\n",
    "\n",
    "def check_attn_output():\n",
    "    for k, v in partial['tp'].items():\n",
    "        print(k, v.shape)\n",
    "    for k, v in partial['ga'].items():\n",
    "        print(k, v.shape)\n",
    "    \n",
    "    ao_tp = sum([partial['tp'][name] for name in names])\n",
    "    ao_ga = torch.cat([partial['ga'][name] for name in names], dim=-2)\n",
    "    print(ao_tp)\n",
    "    print(ao_ga)\n",
    "    print(torch.allclose(ao_tp, ao_ga, atol=2e-3))\n",
    "\n",
    "check_attn_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "eec24458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank1_after_residual1 torch.Size([1, 140, 4096])\n",
      "rank2_after_residual1 torch.Size([1, 140, 4096])\n",
      "rank3_after_residual1 torch.Size([1, 140, 4096])\n",
      "rank4_after_residual1 torch.Size([1, 140, 4096])\n",
      "rank1_after_residual1 torch.Size([1, 35, 4096])\n",
      "rank2_after_residual1 torch.Size([1, 35, 4096])\n",
      "rank3_after_residual1 torch.Size([1, 35, 4096])\n",
      "rank4_after_residual1 torch.Size([1, 35, 4096])\n",
      "True\n",
      "tensor([[[ 0.0495, -0.1875,  0.0240,  ...,  0.2688,  0.2341, -0.2415],\n",
      "         [ 0.3242,  0.4155, -0.5698,  ...,  0.2715, -0.2754,  0.6943],\n",
      "         [-1.4766,  1.6270, -0.1108,  ...,  0.3589,  0.4507,  0.0303],\n",
      "         ...,\n",
      "         [ 0.1985, -0.2493,  0.7705,  ...,  0.4900, -0.9355,  2.0117],\n",
      "         [-0.5596, -1.9844, -0.7822,  ..., -1.7188, -0.5840,  1.8242],\n",
      "         [-0.3687,  1.1904, -0.7637,  ..., -1.1982, -1.1523,  1.3105]]],\n",
      "       dtype=torch.float16)\n",
      "tensor([[[ 0.0493, -0.1855,  0.0235,  ...,  0.2688,  0.2333, -0.2402],\n",
      "         [ 0.3262,  0.4163, -0.5728,  ...,  0.2715, -0.2734,  0.6953],\n",
      "         [-1.4844,  1.6299, -0.1130,  ...,  0.3623,  0.4512,  0.0305],\n",
      "         ...,\n",
      "         [ 0.2030, -0.2463,  0.7715,  ...,  0.4900, -0.9355,  2.0098],\n",
      "         [-0.5576, -1.9854, -0.7832,  ..., -1.7256, -0.5820,  1.8213],\n",
      "         [-0.3674,  1.1885, -0.7690,  ..., -1.1934, -1.1572,  1.3076]]],\n",
      "       dtype=torch.float16)\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# after_residual1\n",
    "pt = 'after_residual1'\n",
    "names, partial = get_partial_results(pt)\n",
    "\n",
    "def check_after_residual1():\n",
    "    for k, v in partial['tp'].items():\n",
    "        print(k, v.shape)\n",
    "    for k, v in partial['ga'].items():\n",
    "        print(k, v.shape)\n",
    "\n",
    "    residual_tp = [partial['tp'][name] for name in names]\n",
    "    print(all_tensors_equal(residual_tp))\n",
    "    residual_ga = torch.cat([partial['ga'][name] for name in names], dim=-2)\n",
    "    print(residual_tp[0])\n",
    "    print(residual_ga)\n",
    "    print(torch.allclose(residual_tp[0], residual_ga, atol=4e-3))\n",
    "\n",
    "check_after_residual1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "34da9aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank1_postnorm torch.Size([1, 140, 4096])\n",
      "rank2_postnorm torch.Size([1, 140, 4096])\n",
      "rank3_postnorm torch.Size([1, 140, 4096])\n",
      "rank4_postnorm torch.Size([1, 140, 4096])\n",
      "rank1_postnorm torch.Size([1, 35, 4096])\n",
      "rank2_postnorm torch.Size([1, 35, 4096])\n",
      "rank3_postnorm torch.Size([1, 35, 4096])\n",
      "rank4_postnorm torch.Size([1, 35, 4096])\n",
      "True\n",
      "tensor([[[ 0.0071, -0.0269,  0.0035,  ...,  0.0375,  0.0316, -0.0342],\n",
      "         [ 0.1134,  0.1453, -0.2020,  ...,  0.0923, -0.0906,  0.2394],\n",
      "         [-0.5449,  0.6006, -0.0415,  ...,  0.1289,  0.1565,  0.0110],\n",
      "         ...,\n",
      "         [ 0.0651, -0.0818,  0.2563,  ...,  0.1564, -0.2888,  0.6509],\n",
      "         [-0.1840, -0.6523, -0.2607,  ..., -0.5498, -0.1808,  0.5918],\n",
      "         [-0.1018,  0.3289, -0.2137,  ..., -0.3218, -0.2996,  0.3569]]],\n",
      "       dtype=torch.float16)\n",
      "tensor([[[ 0.0071, -0.0267,  0.0034,  ...,  0.0376,  0.0316, -0.0341],\n",
      "         [ 0.1140,  0.1455, -0.2030,  ...,  0.0923, -0.0900,  0.2399],\n",
      "         [-0.5479,  0.6016, -0.0423,  ...,  0.1301,  0.1566,  0.0111],\n",
      "         ...,\n",
      "         [ 0.0666, -0.0808,  0.2566,  ...,  0.1564, -0.2888,  0.6504],\n",
      "         [-0.1833, -0.6528, -0.2610,  ..., -0.5518, -0.1801,  0.5908],\n",
      "         [-0.1015,  0.3281, -0.2153,  ..., -0.3206, -0.3005,  0.3562]]],\n",
      "       dtype=torch.float16)\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# postnorm\n",
    "pt = 'postnorm'\n",
    "names, partial = get_partial_results(pt)\n",
    "\n",
    "\n",
    "\n",
    "def check_postnorm():\n",
    "    for k, v in partial['tp'].items():\n",
    "        print(k, v.shape)\n",
    "    for k, v in partial['ga'].items():\n",
    "        print(k, v.shape)\n",
    "    \n",
    "    pns_tp = [partial['tp'][name] for name in names]\n",
    "    print(all_tensors_equal(pns_tp))\n",
    "    pn_ga = torch.cat([partial['ga'][name] for name in names], dim=-2)\n",
    "    print(pns_tp[0])\n",
    "    print(pn_ga)\n",
    "    print(torch.allclose(pns_tp[0], pn_ga, atol=4e-3))\n",
    "\n",
    "check_postnorm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "d56f3dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 140, 11008])\n",
      "torch.Size([1, 140, 11008])\n",
      "tensor([[[-9.0942e-03,  3.0701e-02, -1.8829e-02,  ..., -7.2365e-03,\n",
      "          -1.0155e-02,  5.0621e-03],\n",
      "         [ 6.6910e-03, -4.0894e-03, -1.2286e-01,  ..., -6.5369e-02,\n",
      "           2.3767e-01, -6.8298e-02],\n",
      "         [ 3.2496e-04, -2.1716e-01, -1.8591e-01,  ..., -2.5122e-01,\n",
      "           5.7324e-01,  2.1500e-02],\n",
      "         ...,\n",
      "         [ 4.8126e-02, -1.0361e+00, -5.7007e-02,  ..., -7.0020e-01,\n",
      "           5.2148e-01,  1.9690e-01],\n",
      "         [ 2.7725e-02,  2.9861e-02,  4.9292e-01,  ..., -7.5195e-02,\n",
      "           5.5225e-01, -1.3879e-01],\n",
      "         [ 3.6523e-01, -4.4098e-02,  1.1017e-01,  ...,  1.7471e-02,\n",
      "           7.7100e-01, -4.7302e-02]]], dtype=torch.float16)\n",
      "tensor([[[-9.0485e-03,  3.0518e-02, -1.8524e-02,  ..., -7.2021e-03,\n",
      "          -1.0086e-02,  5.0888e-03],\n",
      "         [ 6.6719e-03, -4.1733e-03, -1.2256e-01,  ..., -6.5491e-02,\n",
      "           2.3792e-01, -6.8298e-02],\n",
      "         [ 4.2343e-04, -2.1655e-01, -1.8567e-01,  ..., -2.5146e-01,\n",
      "           5.7373e-01,  2.1820e-02],\n",
      "         ...,\n",
      "         [ 4.8859e-02, -1.0449e+00, -5.7190e-02,  ..., -7.0166e-01,\n",
      "           5.2100e-01,  1.9739e-01],\n",
      "         [ 2.7847e-02,  2.9465e-02,  4.9292e-01,  ..., -7.5684e-02,\n",
      "           5.5273e-01, -1.3867e-01],\n",
      "         [ 3.6646e-01, -4.3457e-02,  1.1047e-01,  ...,  1.6907e-02,\n",
      "           7.7246e-01, -4.6875e-02]]], dtype=torch.float16)\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# up_proj\n",
    "pt = 'up_proj'\n",
    "names, partial = get_partial_results(pt)\n",
    "\n",
    "def check_up_proj():\n",
    "    # for k, v in partial['tp'].items():\n",
    "    #     print(k, v.shape)\n",
    "    # for k, v in partial['ga'].items():\n",
    "    #     print(k, v.shape)\n",
    "    \n",
    "    tp_up = torch.cat([partial['tp'][name] for name in names], dim=-1)\n",
    "    ga_up = torch.cat([partial['ga'][name] for name in names], dim=-1)\n",
    "    print(tp_up.shape)\n",
    "    print(ga_up.shape)\n",
    "    print(tp_up)\n",
    "    print(ga_up)\n",
    "    print(torch.allclose(tp_up, ga_up, rtol=0.1, atol=1e-5))\n",
    "\n",
    "check_up_proj()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "d3d63cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 3.7817e-01,  7.4036e-02, -1.8311e-03,  ..., -2.4097e-01,\n",
      "          -2.3267e-01,  3.0566e-01],\n",
      "         [-5.8008e-01,  9.7070e-01, -3.5840e-01,  ...,  3.0566e-01,\n",
      "          -2.3486e-01,  7.9248e-01],\n",
      "         [ 3.8916e-01, -1.3164e+00,  6.9385e-01,  ...,  7.0312e-02,\n",
      "           6.2158e-01, -6.8750e-01],\n",
      "         ...,\n",
      "         [ 2.8672e+00,  5.4492e-01, -2.4082e+00,  ...,  3.8330e-01,\n",
      "          -5.0488e-01, -4.0771e-01],\n",
      "         [-2.3633e-01,  1.4531e+00,  7.3145e-01,  ...,  4.3457e-01,\n",
      "          -1.4832e-01, -4.0332e-01],\n",
      "         [-1.7676e-01,  1.2402e+00, -2.4512e-01,  ...,  1.5781e+00,\n",
      "          -2.7246e-01, -3.0762e-02]]], dtype=torch.float16)\n",
      "tensor([[[ 3.7769e-01,  7.3975e-02, -2.0752e-03,  ..., -2.4072e-01,\n",
      "          -2.3267e-01,  3.0518e-01],\n",
      "         [-5.8057e-01,  9.7119e-01, -3.5889e-01,  ...,  3.0420e-01,\n",
      "          -2.3438e-01,  7.9248e-01],\n",
      "         [ 3.9160e-01, -1.3184e+00,  6.9434e-01,  ...,  6.9946e-02,\n",
      "           6.2256e-01, -6.8750e-01],\n",
      "         ...,\n",
      "         [ 2.8652e+00,  5.4785e-01, -2.4023e+00,  ...,  3.7891e-01,\n",
      "          -5.0635e-01, -4.0723e-01],\n",
      "         [-2.3621e-01,  1.4541e+00,  7.3486e-01,  ...,  4.3701e-01,\n",
      "          -1.4856e-01, -4.0332e-01],\n",
      "         [-1.7798e-01,  1.2402e+00, -2.4438e-01,  ...,  1.5801e+00,\n",
      "          -2.7002e-01, -2.9297e-02]]], dtype=torch.float16)\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# down_proj\n",
    "pt = 'down_proj'\n",
    "names, partial = get_partial_results(pt)\n",
    "\n",
    "# preivous layers\n",
    "# def check_down_proj():\n",
    "# # def check_attn_output():\n",
    "#     # for k, v in partial['tp'].items():\n",
    "#     #     print(k, v.shape)\n",
    "#     # for k, v in partial['ga'].items():\n",
    "#     #     print(k, v.shape)\n",
    "    \n",
    "#     dp_tp = sum([partial['tp'][name] for name in names])\n",
    "#     dp_ga = torch.cat([partial['ga'][name] for name in names], dim=-2)\n",
    "#     print(dp_tp)\n",
    "#     print(dp_ga)\n",
    "#     print(torch.allclose(dp_tp, dp_ga, atol=1e-3))\n",
    "\n",
    "# last layer\n",
    "def check_down_proj():\n",
    "    dp_tp = sum([partial['tp'][name] for name in names])\n",
    "    dp_ga = sum([partial['ga'][name] for name in names])\n",
    "    print(dp_tp)\n",
    "    print(dp_ga)\n",
    "    print(torch.allclose(dp_tp, dp_ga, rtol=2e-1))\n",
    "\n",
    "check_down_proj()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "47f38466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "tensor([[[ 4.2749e-01, -1.1340e-01,  2.2141e-02,  ...,  2.7832e-02,\n",
      "           1.5869e-03,  6.3965e-02],\n",
      "         [-2.5635e-01,  1.3867e+00, -9.2822e-01,  ...,  5.7764e-01,\n",
      "          -5.1025e-01,  1.4873e+00],\n",
      "         [-1.0879e+00,  3.1152e-01,  5.8252e-01,  ...,  4.2920e-01,\n",
      "           1.0723e+00, -6.5723e-01],\n",
      "         ...,\n",
      "         [ 3.0664e+00,  2.9517e-01, -1.6377e+00,  ...,  8.7354e-01,\n",
      "          -1.4414e+00,  1.6055e+00],\n",
      "         [-7.9590e-01, -5.3125e-01, -5.0781e-02,  ..., -1.2842e+00,\n",
      "          -7.3242e-01,  1.4209e+00],\n",
      "         [-5.4590e-01,  2.4297e+00, -1.0088e+00,  ...,  3.7891e-01,\n",
      "          -1.4248e+00,  1.2793e+00]]], dtype=torch.float16)\n",
      "tensor([[[ 4.2676e-01, -1.1163e-01,  2.1393e-02,  ...,  2.7954e-02,\n",
      "           6.1035e-04,  6.4819e-02],\n",
      "         [-2.5488e-01,  1.3867e+00, -9.3164e-01,  ...,  5.7617e-01,\n",
      "          -5.0781e-01,  1.4873e+00],\n",
      "         [-1.0928e+00,  3.1055e-01,  5.8105e-01,  ...,  4.3213e-01,\n",
      "           1.0742e+00, -6.5674e-01],\n",
      "         ...,\n",
      "         [ 3.0684e+00,  3.0127e-01, -1.6328e+00,  ...,  8.6914e-01,\n",
      "          -1.4414e+00,  1.6016e+00],\n",
      "         [-7.9395e-01, -5.3125e-01, -4.7852e-02,  ..., -1.2891e+00,\n",
      "          -7.3047e-01,  1.4180e+00],\n",
      "         [-5.4541e-01,  2.4297e+00, -1.0137e+00,  ...,  3.8672e-01,\n",
      "          -1.4277e+00,  1.2783e+00]]], dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "# after_residual2\n",
    "pt = 'after_residual2'\n",
    "names, partial = get_partial_results(pt)\n",
    "\n",
    "# last_layer\n",
    "def check_after_residual2():\n",
    "    # for k, v in partial['tp'].items():\n",
    "    #     print(k, v.shape)\n",
    "    # for k, v in partial['ga'].items():\n",
    "    #     print(k, v.shape)\n",
    "    ar2_tp = [partial['tp'][name] for name in names]\n",
    "    ar2_ga = [partial['ga'][name] for name in names]\n",
    "    print(all_tensors_equal(ar2_tp))\n",
    "    print(all_tensors_equal(ar2_ga))\n",
    "    print(ar2_tp[0])\n",
    "    print(ar2_ga[0])\n",
    "\n",
    "check_after_residual2()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opt-tree",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
